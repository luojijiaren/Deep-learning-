{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#==================EXTRACTING AND ANALYSING DATA FROM .mat FILES===============\n",
    "\"\"\"\n",
    "X and Y Components of Training and Testing Data\n",
    "\"\"\"\n",
    "train_data = scipy.io.loadmat('train_32x32.mat')['X']\n",
    "train_labels = scipy.io.loadmat('train_32x32.mat')['y']\n",
    "test_data = scipy.io.loadmat('test_32x32.mat')['X']\n",
    "test_labels = scipy.io.loadmat('test_32x32.mat')['y']\n",
    "shape_train = train_data.shape\n",
    "shape_test = test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformat(data):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    \n",
    "    return xtrain\n",
    "train_data = reformat(train_data)\n",
    "test_data = reformat(test_data)\n",
    "train_labels=tf.one_hot(indices=train_labels,depth=10)\n",
    "test_labels=tf.one_hot(indices=test_labels,depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot_9:0' shape=(26032, 1, 10) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "width = 32\n",
    "height = 32\n",
    "channels = 3\n",
    "\n",
    "n_labels = 10\n",
    "patch = 5\n",
    "depth = 16\n",
    "hidden = 128\n",
    "dropout = 0.9375\n",
    "\n",
    "batch = 16\n",
    "learning_rate = 0.001\n",
    "tf_train_dataset = tf.placeholder(tf.float32, shape=(None, width, height, channels))\n",
    "#Training Labels\n",
    "tf_train_labels = tf.placeholder(tf.float32, shape=(None, n_labels))\n",
    "#Testing Dataset\n",
    "tf_test_dataset = tf.constant(test_data)\n",
    "\n",
    "#   Layer 1: (5, 5, 3, 16)\n",
    "layer1_weights = tf.Variable(tf.truncated_normal([patch, patch, channels, depth], stddev=0.1))\n",
    "layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "\n",
    "#   Layer 2: (5, 5, 16, 16)\n",
    "layer2_weights = tf.Variable(tf.truncated_normal([patch, patch, depth, depth], stddev=0.1))\n",
    "layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "\n",
    "#   Layer 3: (1024, 128)\n",
    "layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, hidden], stddev=0.1))\n",
    "layer3_biases = tf.Variable(tf.constant(1.0, shape=[hidden]))\n",
    "\n",
    "#   Layer 4: (128, 10)\n",
    "layer4_weights = tf.Variable(tf.truncated_normal([hidden, n_labels], stddev=0.1))\n",
    "layer4_biases = tf.Variable(tf.constant(1.0, shape=[n_labels]))\n",
    "\n",
    "dropout = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGHCAYAAABxmBIgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVmkuVszMzKzS/h+4mPXSHUQQBwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22304c70908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_labels = train_labels.reshape(73257).tolist()\n",
    "temp_labels = dict(Counter(temp_labels))\n",
    "plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', label='Training Labels')\n",
    "plt.xticks(range(len(temp_labels)), temp_labels.keys())\n",
    "temp_labels = test_labels.reshape(26032).tolist()\n",
    "temp_labels = dict(Counter(temp_labels))\n",
    "plt.bar(range(len(temp_labels)), temp_labels.values(), align='center', color='red', label='Testing Labels')\n",
    "plt.legend()\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of Class Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 5099,\n",
       " 2: 4149,\n",
       " 3: 2882,\n",
       " 4: 2523,\n",
       " 5: 2384,\n",
       " 6: 1977,\n",
       " 7: 2019,\n",
       " 8: 1660,\n",
       " 9: 1595,\n",
       " 10: 1744}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73257 Images with 32 x 32 RGB grid\n"
     ]
    }
   ],
   "source": [
    "print(shape_train[3], \"Images with\", shape_train[0], \"x\", shape_train[0], \"RGB grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot_1:0' shape=(5, 5) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=tf.one_hot(\n",
    "indices=[0,1,2,3,4],\n",
    "depth=5)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    xtrain = []\n",
    "    trainLen = train_data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(train_data[:,:,:,x])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73257, 32, 32, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot_7:0' shape=(73257, 10, 10) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=tf.one_hot(\n",
    "indices=train_labels,\n",
    "depth=10)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformat(data, Y):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif el==5:\n",
    "            temp[5]=1\n",
    "        elif el==6:\n",
    "            temp[6]=1\n",
    "        elif el==7:\n",
    "            temp[7]=1\n",
    "        elif el==8:\n",
    "            temp[8]=1\n",
    "        elif el==9:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "    return xtrain, np.asarray(Ytr)\n",
    "\n",
    "train_data, train_labels = reformat(train_data, train_labels)\n",
    "test_data, test_labels = reformat(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73257, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'next_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-b26f058e16a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     train_accuracy = accuracy.eval(feed_dict={\n\u001b[1;32m      7\u001b[0m         tf_train_dataset:batch[0], tf_train_labels: batch[1], keep_prob: 1.0})\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'next_batch'"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "print('Initialized')\n",
    "average = 0\n",
    "for i in range(10000):\n",
    "    batch = train_data.next_batch(50)\n",
    "    train_accuracy = accuracy_train.eval(feed_dict={\n",
    "        tf_train_dataset:batch[0], tf_train_labels: batch[1], keep_prob: 1.0})\n",
    "    if (i % 50 == 0):\n",
    "\n",
    "        print(\"step %d, training accuracy %.4f\"%(i, train_accuracy))\n",
    "    average += train_accuracy\n",
    "    optimizer.run(feed_dict={tf_train_dataset: batch[0], tf_train_labels: batch[1], keep_prob: 0.5})\n",
    "    average += accu\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'keep_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-c79cb16efd1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[1;31m#   Dictionary to be fed to TensorFlow Session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     train_accuracy = accuracy.eval(feed_dict={\n\u001b[0;32m---> 16\u001b[0;31m         tf_train_dataset:batch_data, tf_train_labels: batch_labels, keep_prob: 1.0})\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keep_prob' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#   Number of iterations\n",
    "num_steps = 10000\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Initialized')\n",
    "average = 0\n",
    "for step in range(num_steps):\n",
    "    #   Constucting the batch from the data set\n",
    "    offset = (step * batch) % (73257 - batch)\n",
    "    batch_data = train_data[offset:(offset + batch), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch), :]\n",
    "    #   Dictionary to be fed to TensorFlow Session\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        tf_train_dataset:batch_data, tf_train_labels: batch_labels, keep_prob: 1.0})\n",
    "\n",
    "\n",
    "    if (step % 50 == 0):\n",
    "        print('Minibatch loss at step %d: %f' % (step, l))\n",
    "        print('Minibatch accuracy: %.1f%%' % accu)\n",
    "    average += train_accuracy\n",
    "    optimizer.run(feed_dict={tf_train_dataset:batch_data, tf_train_labels: batch_labels, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch accuracy: 0.0%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-0440f2e95e33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m73257\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[1;31m#train_labels = np.asarray( train_labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m73257\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mbatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mbatch_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "#   Number of iterations\n",
    "num_steps = 10000\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Initialized')\n",
    "average = 0\n",
    "for step in range(num_steps):\n",
    "    #   Constucting the batch from the data set\n",
    "    offset = (step * batch) % (73257 - batch)\n",
    "    #train_labels = np.asarray( train_labels)\n",
    "    train_labels=train_labels.eval().reshape(73257,10)\n",
    "    batch_data = train_data[offset:(offset + batch), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch),:]\n",
    "    #   Dictionary to be fed to TensorFlow Session\n",
    "    accu = accuracy_train.eval(feed_dict={\n",
    "        tf_train_dataset : batch_data, tf_train_labels : batch_labels, dropout: 0.93})\n",
    "    #   Calculating the Accuracy of the predictions\n",
    "    #accu = accuracy(predictions, batch_labels)\n",
    "    if (step % 50 == 0):\n",
    "        #print('Minibatch loss at step %d: %f' % (step, l))\n",
    "        print('Minibatch accuracy: %.1f%%' % accu)\n",
    "    average += accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "#==================EXTRACTING AND ANALYSING DATA FROM .mat FILES===============\n",
    "\"\"\"\n",
    "X and Y Components of Training and Testing Data\n",
    "\"\"\"\n",
    "train_data = scipy.io.loadmat('train_32x32.mat')['X']\n",
    "train_labels = scipy.io.loadmat('train_32x32.mat')['y']\n",
    "test_data = scipy.io.loadmat('test_32x32.mat')['X']\n",
    "test_labels = scipy.io.loadmat('test_32x32.mat')['y']\n",
    "\n",
    "train_data = train_data.astype('float32') / 128.0 - 1\n",
    "test_data = test_data.astype('float32') / 128.0 - 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Converting Labels to One Hot Encoding and Image Matrix to favourable dimensions\n",
    "\"\"\"\n",
    "def reformat(data):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    \n",
    "    return xtrain\n",
    "train_data = reformat(train_data)\n",
    "test_data = reformat(test_data)\n",
    "train_labels=tf.one_hot(indices=train_labels,depth=10)\n",
    "test_labels=tf.one_hot(indices=test_labels,depth=10)\n",
    "\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "\n",
    "#==================BUILDING THE CNN==========================================\n",
    "\"\"\"\n",
    "Various Hyperparameters required for training the CNN.\n",
    "\"\"\"\n",
    "image_size = 32\n",
    "width = 32\n",
    "height = 32\n",
    "channels = 3\n",
    "\n",
    "n_labels = 10\n",
    "patch = 5\n",
    "depth = 16\n",
    "hidden = 128\n",
    "dropout = 0.9375\n",
    "\n",
    "batch = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "\"\"\"\n",
    "Constructing the placeholders and variables in the TensorFlow Graph\n",
    "\"\"\"\n",
    "#Training Dataset\n",
    "tf_train_dataset = tf.placeholder(tf.float32, shape=(None, width, height, channels))\n",
    "#Training Labels\n",
    "tf_train_labels = tf.placeholder(tf.float32, shape=(None, n_labels))\n",
    "#Testing Dataset\n",
    "tf_test_dataset = tf.constant(test_data)\n",
    "\n",
    "\n",
    "#   Layer 1: (5, 5, 3, 16)\n",
    "layer1_weights = tf.Variable(tf.truncated_normal([patch, patch, channels, depth], stddev=0.1))\n",
    "layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "\n",
    "#   Layer 2: (5, 5, 16, 16)\n",
    "layer2_weights = tf.Variable(tf.truncated_normal([patch, patch, depth, depth], stddev=0.1))\n",
    "layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "\n",
    "#   Layer 3: (1024, 128)\n",
    "layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, hidden], stddev=0.1))\n",
    "layer3_biases = tf.Variable(tf.constant(1.0, shape=[hidden]))\n",
    "\n",
    "#   Layer 4: (128, 10)\n",
    "layer4_weights = tf.Variable(tf.truncated_normal([hidden, n_labels], stddev=0.1))\n",
    "layer4_biases = tf.Variable(tf.constant(1.0, shape=[n_labels]))\n",
    "\n",
    "dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "def model(data):\n",
    "    #   Convolution 1 and RELU\n",
    "    conv1 = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv1 + layer1_biases)\n",
    "    #   Max Pool\n",
    "    hidden2 = tf.nn.max_pool(hidden1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    #   Convolution 2 and RELU\n",
    "    conv2 = tf.nn.conv2d(hidden2, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden3 = tf.nn.relu(conv2 + layer2_biases)\n",
    "    #   Max Pool\n",
    "    hidden4 = tf.nn.max_pool(hidden3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    shape = hidden4.get_shape().as_list()\n",
    "\n",
    "    reshape = tf.reshape(hidden4, [-1, shape[1] * shape[2] * shape[3]])\n",
    "    hidden5 = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    #   Dropout\n",
    "    dropout_layer = tf.nn.dropout(hidden5, 0.93)\n",
    "    \n",
    "    return tf.matmul(dropout_layer, layer4_weights) + layer4_biases\n",
    "\n",
    "logits = model(tf_train_dataset)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "correct_prediction_train = tf.equal(tf.argmax(train_prediction,1), tf.argmax(tf_train_labels,1))\n",
    "accuracy_train = tf.reduce_mean(tf.cast(correct_prediction_train, tf.float32))\n",
    "#correct_prediction_test = tf.equal(tf.argmax(test_prediction,1), tf.argmax(tf_test_labels,1))\n",
    "#accuracy_test = tf.reduce_mean(tf.cast(correct_prediction_test, tf.float32))\n",
    "#tf_test_labels=tf.constant(test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_7:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 6.187049\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 50: 2.253537\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 100: 2.319354\n",
      "Minibatch accuracy: 18.8%\n",
      "Minibatch loss at step 150: 2.314340\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 200: 2.305859\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 250: 2.716376\n",
      "Minibatch accuracy: 18.8%\n",
      "Minibatch loss at step 300: 3.347036\n",
      "Minibatch accuracy: 18.8%\n",
      "Minibatch loss at step 350: 5.162056\n",
      "Minibatch accuracy: 18.8%\n",
      "Minibatch loss at step 400: 71.321732\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 450: 330.279480\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 500: 851.165527\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 550: 719.447510\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 600: 4496.596680\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 650: 3597.019531\n",
      "Minibatch accuracy: 25.0%\n",
      "Minibatch loss at step 700: 17144.402344\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 750: 12098.345703\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 800: 31085.726562\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 850: 18998.871094\n",
      "Minibatch accuracy: 18.8%\n",
      "Minibatch loss at step 900: 43771.988281\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 950: 85497.414062\n",
      "Minibatch accuracy: 25.0%\n",
      "Minibatch loss at step 1000: 73887.546875\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1050: 35327.566406\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1100: 120079.500000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1150: 140626.750000\n",
      "Minibatch accuracy: 31.2%\n",
      "Minibatch loss at step 1200: 256517.890625\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 1250: 113152.398438\n",
      "Minibatch accuracy: 18.8%\n",
      "Minibatch loss at step 1300: 173161.062500\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1350: 33398.187500\n",
      "Minibatch accuracy: 43.8%\n",
      "Minibatch loss at step 1400: 322674.875000\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 1450: 219120.062500\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1500: 435414.031250\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1550: 366005.375000\n",
      "Minibatch accuracy: 25.0%\n",
      "Minibatch loss at step 1600: 861446.125000\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 1650: 494520.406250\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 1700: 1783255.750000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1750: 1482332.750000\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 1800: 605769.750000\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 1850: 506764.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 1900: 683036.250000\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 1950: 798176.687500\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 2000: 381437.781250\n",
      "Minibatch accuracy: 18.8%\n",
      "Minibatch loss at step 2050: 767765.750000\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 2100: 1801185.250000\n",
      "Minibatch accuracy: 18.8%\n",
      "Minibatch loss at step 2150: 2385778.250000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 2200: 1044639.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 2250: 480486.312500\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 2300: 1479469.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 2350: 1062968.750000\n",
      "Minibatch accuracy: 25.0%\n",
      "Minibatch loss at step 2400: 2816937.000000\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 2450: 1602615.125000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 2500: 1461341.375000\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 2550: 3494316.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 2600: 3895420.000000\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 2650: 3621981.750000\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 2700: 1672179.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 2750: 2980620.000000\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 2800: 1221011.750000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 2850: 3854899.500000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 2900: 3235282.250000\n",
      "Minibatch accuracy: 25.0%\n",
      "Minibatch loss at step 2950: 3610494.750000\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 3000: 2911956.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 3050: 3599281.250000\n",
      "Minibatch accuracy: 6.2%\n",
      "Minibatch loss at step 3100: 1285346.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Minibatch loss at step 3150: 1357853.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 3200: 3650906.500000\n",
      "Minibatch accuracy: 25.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-8b096daf128f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[1;31m#   Dictionary to be fed to TensorFlow Session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.93\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[1;31m#   Calculating the Accuracy of the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0maccu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "#   Number of iterations\n",
    "num_steps = 10000\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Initialized')\n",
    "average = 0\n",
    "for step in range(num_steps):\n",
    "    #   Constucting the batch from the data set\n",
    "    offset = (step * batch) % (73257 - batch)\n",
    "    batch_data = train_data[offset:(offset + batch), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch), :]\n",
    "    #   Dictionary to be fed to TensorFlow Session\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, dropout: 0.93}\n",
    "    _, l, predictions = sess.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    #   Calculating the Accuracy of the predictions\n",
    "    accu = accuracy(predictions, batch_labels)\n",
    "    if (step % 50 == 0):\n",
    "        print('Minibatch loss at step %d: %f' % (step, l))\n",
    "        print('Minibatch accuracy: %.1f%%' % accu)\n",
    "    average += accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GraphDef cannot be larger than 2GB.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-1a0790d0039b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;31m#==================EXTRACTING AND ANALYSING DATA FROM .mat FILES===============\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \"\"\"\n\u001b[0;32m-> 1449\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3666\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3667\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3668\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    997\u001b[0m                 run_metadata):\n\u001b[1;32m    998\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         graph_def, self._current_version = self._graph._as_graph_def(\n\u001b[1;32m   1042\u001b[0m             \u001b[0mfrom_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             add_shapes=self._add_shapes)\n\u001b[0m\u001b[1;32m   1044\u001b[0m         \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fzhan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   2066\u001b[0m           \u001b[0mbytesize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m<<\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2068\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GraphDef cannot be larger than 2GB.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2069\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GraphDef cannot be larger than 2GB."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "#==================EXTRACTING AND ANALYSING DATA FROM .mat FILES===============\n",
    "\"\"\"\n",
    "X and Y Components of Training and Testing Data\n",
    "\"\"\"\n",
    "train_data = scipy.io.loadmat('train_32x32.mat')['X']\n",
    "train_labels = scipy.io.loadmat('train_32x32.mat')['y']\n",
    "test_data = scipy.io.loadmat('test_32x32.mat')['X']\n",
    "test_labels = scipy.io.loadmat('test_32x32.mat')['y']\n",
    "\n",
    "train_data = train_data.astype('float32') / 128.0 - 1\n",
    "test_data = test_data.astype('float32') / 128.0 - 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Converting Labels to One Hot Encoding and Image Matrix to favourable dimensions\n",
    "\"\"\"\n",
    "def reformat(data):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    \n",
    "    return xtrain\n",
    "train_data = reformat(train_data)\n",
    "test_data = reformat(test_data)\n",
    "train_labels=tf.one_hot(indices=train_labels,depth=10)\n",
    "train_labels=train_labels.eval().reshape(73257,10)\n",
    "test_labels=tf.one_hot(indices=test_labels,depth=10)\n",
    "train_labels=train_labels.eval().reshape(26032,10)\n",
    "\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "\n",
    "#==================BUILDING THE CNN==========================================\n",
    "\"\"\"\n",
    "Various Hyperparameters required for training the CNN.\n",
    "\"\"\"\n",
    "image_size = 32\n",
    "width = 32\n",
    "height = 32\n",
    "channels = 3\n",
    "\n",
    "n_labels = 10\n",
    "patch = 5\n",
    "depth = 16\n",
    "hidden = 128\n",
    "dropout = 0.9375\n",
    "\n",
    "batch = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "\"\"\"\n",
    "Constructing the placeholders and variables in the TensorFlow Graph\n",
    "\"\"\"\n",
    "#Training Dataset\n",
    "tf_train_dataset = tf.placeholder(tf.float32, shape=(None, width, height, channels))\n",
    "#Training Labels\n",
    "tf_train_labels = tf.placeholder(tf.float32, shape=(None, n_labels))\n",
    "#Testing Dataset\n",
    "tf_test_dataset = tf.constant(test_data)\n",
    "\n",
    "#   Layer 1: (5, 5, 3, 16)\n",
    "layer1_weights = tf.Variable(tf.truncated_normal([patch, patch, channels, depth], stddev=0.1))\n",
    "layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "\n",
    "#   Layer 2: (5, 5, 16, 16)\n",
    "layer2_weights = tf.Variable(tf.truncated_normal([patch, patch, depth, depth], stddev=0.1))\n",
    "layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "\n",
    "#   Layer 3: (1024, 128)\n",
    "layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, hidden], stddev=0.1))\n",
    "layer3_biases = tf.Variable(tf.constant(1.0, shape=[hidden]))\n",
    "\n",
    "#   Layer 4: (128, 10)\n",
    "layer4_weights = tf.Variable(tf.truncated_normal([hidden, n_labels], stddev=0.1))\n",
    "layer4_biases = tf.Variable(tf.constant(1.0, shape=[n_labels]))\n",
    "\n",
    "dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "def model(data):\n",
    "    #   Convolution 1 and RELU\n",
    "    conv1 = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv1 + layer1_biases)\n",
    "    #   Max Pool\n",
    "    hidden2 = tf.nn.max_pool(hidden1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    #   Convolution 2 and RELU\n",
    "    conv2 = tf.nn.conv2d(hidden2, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden3 = tf.nn.relu(conv2 + layer2_biases)\n",
    "    #   Max Pool\n",
    "    hidden4 = tf.nn.max_pool(hidden3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    shape = hidden4.get_shape().as_list()\n",
    "\n",
    "    reshape = tf.reshape(hidden4, [-1, shape[1] * shape[2] * shape[3]])\n",
    "    hidden5 = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    #   Dropout\n",
    "    dropout_layer = tf.nn.dropout(hidden5, 0.93)\n",
    "    \n",
    "    return tf.matmul(dropout_layer, layer4_weights) + layer4_biases\n",
    "\n",
    "logits = model(tf_train_dataset)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "#============================================================================\n",
    "\n",
    "#==================TRAINING AND TESTING THE MODEL============================\n",
    "\"\"\"\n",
    "Accuracy function defined similar to the one taught in the Udacity Deep Learning Course\n",
    "Returns percentage of correct predictions by verifying with Labels\n",
    "\"\"\"\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "#   Number of iterations\n",
    "num_steps = 10000\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Initialized')\n",
    "average = 0\n",
    "for step in range(num_steps):\n",
    "    #   Constucting the batch from the data set\n",
    "    offset = (step * batch) % (73257 - batch)\n",
    "    batch_data = train_data[offset:(offset + batch), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch), :]\n",
    "    #   Dictionary to be fed to TensorFlow Session\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, dropout: 0.93}\n",
    "    _, l, predictions = sess.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    #   Calculating the Accuracy of the predictions\n",
    "    accu = accuracy(predictions, batch_labels)\n",
    "    if (step % 50 == 0):\n",
    "        print('Minibatch loss at step %d: %f' % (step, l))\n",
    "        print('Minibatch accuracy: %.1f%%' % accu)\n",
    "    average += accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
